# configs/synthetic_dataset_creation/high_constraint_run.yaml

# Tells the loader which grammar "world" to use.
grammar_profile: "high_constraint_grammar"
ebnf_file: "strict_structures.ebnf"

# This entire block will be passed to the Planner
planner_config:
  name: "High-Constraint Grammar"

  # A lower threshold is fine; we expect fewer unique structures.
  plan_deduplication_threshold: 0.90
  # Enforce a progressive sequence of points, adding another layer of constraint.
  enforce_plan_points_progression: false

# High-level run params
num: 499
outfile_template: "data/processed/high_constraint_grammar/high_constraint_{num}.jsonl"
seed: 43
log_skips: false

# Controls JSON output formatting. Set to a number (e.g., 4) for pretty-printing,
# or false for compact, single-line output.
json_indent: false

# Exhaustion / attempts
max_attempts_multiplier: 100.0
consecutive_dup_limit: 5000

# Exact dedup (hash)
dedup_by: plan     # plan | text | none

# Jaccard near-dup
jaccard_dedup: true
jaccard_ngram: 2
jaccard_threshold: 0.90
jaccard_window: 500

# Semantic near-dup
semantic_dedup: true
semantic_threshold: 0.95
semantic_model: sentence-transformers/all-MiniLM-L6-v2
semantic_device: null  # "cpu" | "cuda" | null for auto